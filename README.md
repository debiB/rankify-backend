# RankifyTrack Backend

Express.js server with TypeScript, tRPC, Prisma, and JWT authentication.

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+
- MySQL database
- npm

### Installation

1. **Install dependencies**
   ```bash
   npm install
   ```

2. **Set up environment variables**
   ```bash
   cp env.example .env
   ```
   Edit `.env` with your database credentials and JWT secret.

3. **Set up database**
   ```bash
   # Generate Prisma client
   npm run db:generate
   
   # Push schema to database
   npm run db:push
   ```

4. **Start development server**
   ```bash
   npm run dev
   ```

## ğŸ“ Project Structure

```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ controllers/     # Route controllers
â”‚   â”œâ”€â”€ middleware/      # Custom middleware
â”‚   â”œâ”€â”€ routes/          # Express routes
â”‚   â”œâ”€â”€ services/        # Business logic
â”‚   â”œâ”€â”€ utils/           # Utility functions
â”‚   â”‚   â””â”€â”€ auth.ts      # Authentication utilities
â”‚   â”œâ”€â”€ trpc/            # tRPC configuration
â”‚   â”‚   â”œâ”€â”€ context.ts   # tRPC context
â”‚   â”‚   â””â”€â”€ router.ts    # tRPC router
â”‚   â””â”€â”€ app.ts           # Main application
â”œâ”€â”€ prisma/
â”‚   â””â”€â”€ schema.prisma    # Database schema
â”œâ”€â”€ tests/               # Test files
â””â”€â”€ dist/                # Compiled JavaScript
```

## ğŸ”§ Available Scripts

- `npm run dev` - Start development server with hot reload
- `npm run build` - Build TypeScript to JavaScript
- `npm run start` - Start production server
- `npm run db:generate` - Generate Prisma client
- `npm run db:push` - Push schema changes to database
- `npm run db:migrate` - Create and apply migrations
- `npm run db:studio` - Open Prisma Studio

## ğŸ” Authentication

The server uses JWT authentication with the following endpoints:

- `POST /trpc/register` - Register new user
- `POST /trpc/login` - Login user
- `GET /trpc/getProfile` - Get user profile (protected)
- `GET /trpc/getUsers` - Get all users (protected)

## ğŸŒ API Endpoints

- `GET /health` - Health check endpoint

## ğŸ”’ Environment Variables

Required environment variables in `.env`:

```env
DATABASE_URL="mysql://username:password@localhost:3306/rank_ranger"
JWT_SECRET="your-super-secret-jwt-key-at-least-32-characters-long"
JWT_EXPIRES_IN="7d"
PORT=3001
NODE_ENV=development
CORS_ORIGIN="http://localhost:3000"
```

## ğŸ› ï¸ Development

The server runs on port 3001 by default. Make sure your MySQL database is running and the connection string in `.env` is correct.

For development, the server will automatically restart when you make changes to the source code. 

## ğŸ“Š Search Console Data Model & Aggregation (New)

### Monthly Keyword Metrics (Persistence)
- We persist per-month keyword metrics in `SearchConsoleKeywordMonthlyComputed` to avoid calling the Google Search Console (GSC) API on UI refresh.
- For each keyword and month:
  - Window: current month â†’ all available days; past months â†’ last 7 days of that month.
  - Determine a single top page across the window by total impressions.
  - Tie-breakers (in order): daysWithData â†’ clicks â†’ better (lower) avg position â†’ prefer URL without hash â†’ shorter URL â†’ lexicographic.
  - Compute weighted average position using only that pageâ€™s rows: Î£(position Ã— impressions) / Î£(impressions).
  - Upsert result into `SearchConsoleKeywordMonthlyComputed` with `{ topRankingPageUrl, averageRank, impressions, clicks, calcWindowDays }`.

### Read Path (Frontend/API)
- `campaigns.getCampaignAnalytics` reads monthly rank/top page/impressions directly from `SearchConsoleKeywordMonthlyComputed`.
- No GSC calls occur on tab refresh. Missing months remain zero until cron/data-fetch fills them.

### Initial Rank (Baseline)
- On campaign create/update (and re-fetch), we compute an initial rank per keyword from the 7 days before `startingDate`:
  - Select the top page across those 7 days using the same tie-breakers as above.
  - Compute weighted average position using only that pageâ€™s rows.
  - Store in `SearchConsoleKeyword.initialPosition`. Daily rows are kept for diagnostics/search volume.

### Cron & Data Flows
- Cron jobs (monthly/daily) call `fetchDailyKeywordData`, which now also computes/updates `SearchConsoleKeywordMonthlyComputed`.
- `createCampaign`, `updateCampaign` (when startingDate changes), and admin â€œGet All Dataâ€ flows trigger the same computation.

### Data Deletion
- Admin â€œDelete All Dataâ€ deletes in safe FK order:
  1) `SearchConsoleKeywordMonthlyComputed`
  2) `SearchConsoleKeywordMonthlyStat`
  3) `SearchConsoleKeyword`
  4) `SearchConsoleKeywordAnalytics`
  5) `SearchConsoleTrafficDaily`
  6) `SearchConsoleTrafficMonthly`
  7) `SearchConsoleTrafficAnalytics`
- After deletion, use â€œGet All Dataâ€ to repopulate, or wait for cron.